{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Iterable, Optional\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "from utils import DBClients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_search_index_keys(stems: Iterable[str]) -> list[str]:\n",
    "    return [f\"devstop:index:{stem}\" for stem in stems]\n",
    "\n",
    "def get_stem_from_key(key: str) -> str:\n",
    "    return key.split(\":\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_lookup(stems: Iterable[str]) -> dict[str, set[str]]:\n",
    "    keys = gen_search_index_keys(stems)\n",
    "    print(keys)\n",
    "    redis_client = DBClients.redis_client()\n",
    "    index_lkp = {}\n",
    "    for key in keys:\n",
    "        result = redis_client.smembers(key)\n",
    "        if result:\n",
    "            index_lkp[get_stem_from_key(key)] = {doc_id.decode() for doc_id in result}\n",
    "    return index_lkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_freq_keys(lookup: dict[str, set[str]]) -> list[str]:\n",
    "    return [f\"devstop:freq:{stem}:{doc}\" for stem, docs in lookup.items() for doc in docs]\n",
    "    \n",
    "def get_stem_doc_from_key(key: str) -> tuple[str, str]:\n",
    "    split_key = key.split(\":\")\n",
    "    return split_key[2], split_key[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_lookup(lookup: dict[str, set[str]]) -> dict[str, str]:\n",
    "    keys = gen_freq_keys(lookup)\n",
    "    # print(keys)\n",
    "    redis_client = DBClients.redis_client()\n",
    "    results = redis_client.mget(keys)\n",
    "    \n",
    "    # woi --> Words of interests\n",
    "    docs_with_woi = defaultdict(str)\n",
    "    for key, result in zip(keys, results):\n",
    "        stem, doc = get_stem_doc_from_key(key)\n",
    "        docs_with_woi[doc] += \" \" + \" \".join([stem] * int(result))\n",
    "    return docs_with_woi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_stems(query: str) -> list[str]:\n",
    "    stpwords = stopwords.words(\"english\")\n",
    "    tokens = word_tokenize(query)\n",
    "    wnl = WordNetLemmatizer()\n",
    "    return [wnl.lemmatize(tok) for tok in tokens if tok not in stpwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tfidf_matrix(docs_with_woi: dict[str, str], stemmed_query: str) -> csr_matrix:\n",
    "    corpus = list(docs_with_woi.values()) + [stemmed_query]\n",
    "    tfidf_vec = TfidfVectorizer()\n",
    "    doc_term_matrix = tfidf_vec.fit_transform(corpus)\n",
    "    return doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_processor(query: str, num_results: int = 10) -> list[tuple[str, float]]:\n",
    "    stems = get_query_stems(query)\n",
    "    index_lkp = index_lookup(set(stems))\n",
    "    docs_with_woi = frequency_lookup(index_lkp)\n",
    "    tfidf_matrix = gen_tfidf_matrix(docs_with_woi, \" \".join(stems))\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[0:-1], tfidf_matrix[-1]).flatten()\n",
    "    sorted_docs = list(sorted(zip(docs_with_woi.keys(), cosine_sim), key=lambda x: x[1], reverse=True))\n",
    "    return sorted_docs[:min(num_results, len(sorted_docs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document(doc_id: str | list[str]) -> list[dict]:\n",
    "    assert doc_id, \"doc_id cannot be empty\"\n",
    "    if isinstance(doc_id, str):\n",
    "        doc_id = [doc_id]\n",
    "    \n",
    "    reddit_docs = [id.split(\"-\")[1] for id in doc_id if id.startswith(\"reddit\")]\n",
    "    so_docs = [int(id.split(\"-\")[1]) for id in doc_id if id.startswith(\"so\")]\n",
    "    \n",
    "    mongo_client = DBClients.mongo_client()\n",
    "    reddit_collection = mongo_client[\"devstop\"][\"reddit_submissions\"]\n",
    "    so_collection = mongo_client[\"devstop\"][\"so_questions\"]\n",
    "    \n",
    "    reddit_results = reddit_collection.find({\"_id\": {\"$in\": reddit_docs}}) if reddit_docs else []\n",
    "    so_results = so_collection.find({\"_id\": {\"$in\": so_docs}}) if so_docs else []\n",
    "    \n",
    "    all_results = []\n",
    "    for doc in reddit_results:\n",
    "        all_results.append({\"doc_id\": f\"reddit-{doc['_id']}\", \"title\": doc[\"title\"], \"url\": f\"https://reddit.com{doc['permalink']}\"})\n",
    "    for doc in so_results:\n",
    "        all_results.append({\"doc_id\": f\"so-{doc['_id']}\", \"title\": doc[\"title\"], \"url\": doc[\"link\"]})\n",
    "    \n",
    "    return list(sorted(all_results, key=lambda x: doc_id.index(x[\"doc_id\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['devstop:index:variable', 'devstop:index:function', 'devstop:index:looping']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('reddit-t3_gdzu6e', 1.0000000000000002),\n",
       " ('so-6967463', 1.0000000000000002),\n",
       " ('so-13694034', 1.0000000000000002),\n",
       " ('so-9044084', 1.0000000000000002),\n",
       " ('so-3162271', 1.0000000000000002),\n",
       " ('so-41707229', 0.981144197450551),\n",
       " ('so-2081836', 0.9751160439809308),\n",
       " ('so-26666919', 0.9751160439809308),\n",
       " ('so-5518435', 0.9741339462621095),\n",
       " ('so-869885', 0.9723304330440237)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_hits = query_processor(\"function variable looping\")\n",
    "top_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': 'reddit-t3_gdzu6e',\n",
       "  'title': \"Holy heck I'm addicted.\",\n",
       "  'url': 'https://reddit.com/r/learnpython/comments/gdzu6e/holy_heck_im_addicted/'},\n",
       " {'doc_id': 'so-6967463',\n",
       "  'title': 'Iterating over a numpy array',\n",
       "  'url': 'https://stackoverflow.com/questions/6967463/iterating-over-a-numpy-array'},\n",
       " {'doc_id': 'so-13694034',\n",
       "  'title': 'Is a Python list guaranteed to have its elements stay in the order they are inserted in?',\n",
       "  'url': 'https://stackoverflow.com/questions/13694034/is-a-python-list-guaranteed-to-have-its-elements-stay-in-the-order-they-are-inse'},\n",
       " {'doc_id': 'so-9044084',\n",
       "  'title': 'Efficient date range overlap calculation?',\n",
       "  'url': 'https://stackoverflow.com/questions/9044084/efficient-date-range-overlap-calculation'},\n",
       " {'doc_id': 'so-3162271',\n",
       "  'title': 'Get loop count inside a for-loop',\n",
       "  'url': 'https://stackoverflow.com/questions/3162271/get-loop-count-inside-a-for-loop'},\n",
       " {'doc_id': 'so-41707229',\n",
       "  'title': 'tqdm printing to newline',\n",
       "  'url': 'https://stackoverflow.com/questions/41707229/tqdm-printing-to-newline'},\n",
       " {'doc_id': 'so-2081836',\n",
       "  'title': 'How to read specific lines from a file (by line number)?',\n",
       "  'url': 'https://stackoverflow.com/questions/2081836/how-to-read-specific-lines-from-a-file-by-line-number'},\n",
       " {'doc_id': 'so-26666919',\n",
       "  'title': 'Add column in dataframe from list',\n",
       "  'url': 'https://stackoverflow.com/questions/26666919/add-column-in-dataframe-from-list'},\n",
       " {'doc_id': 'so-5518435',\n",
       "  'title': 'Python: fastest way to create a list of n lists',\n",
       "  'url': 'https://stackoverflow.com/questions/5518435/python-fastest-way-to-create-a-list-of-n-lists'},\n",
       " {'doc_id': 'so-869885',\n",
       "  'title': 'Loop backwards using indices',\n",
       "  'url': 'https://stackoverflow.com/questions/869885/loop-backwards-using-indices'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_document([hit[0] for hit in top_hits])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cc0bb42e58ba8a04fc5923e9a0b384551aad937ef11555c508d021797091504"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
